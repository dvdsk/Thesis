\subsection{Consensus Algorithms}
In this world where the network can not be trusted, time lies to us and servers will randomly crash and burn how can we get anything done at all? Let's discuss how we can build a system we can trust, a system that behaves \textit{consistently}. To build such a system we need the parts that make up the system to agree with each other, the must-have: \emph{Consensus}. Here we discuss three well known solutions. Before we get to that lets look at the principle that underlies them all: \emph{The truth is defined by the majority}.

\subsubsection*{Quorums}
Imagine a node hard at work processing requests from its siblings, suddenly it stops. The other nodes notice it is no longer responding and declare it dead, they do not know its threads got paused. A few seconds later the node responds again as if nothing had happened, and unless it checks the system clock, no time has paused from its perspective. Or imagine a network fault partitions the system, each group of servers can reach its members but not others. The nodes in the group will declare those in the other group dead and continue their work. Both these scenarios usually result in data loss, if the work progresses at all.

We can prevent this by voting over each decision. It will be a strange vote, no node cares about the decision itself. In most implementations a node only checks if it regards the sender as trustworthy or alive and then vote yes. To prove liveliness the vote proposal could include a number. Voters only vote yes if the number is correct. For example if the number is the highest they have seen. If a majority votes yes the node that requested the vote can be sure it is, at that instance, not dead or disconnected. This is the idea behind "Quorums," majorities of nodes that vote.

\subsubsection*{Paxos}
The \paxos{} algorithm~\cite{paxos} uses a quorum to provide consensus. It enables us to choose a single value among proposals such that only that value can be read as the accepted value. Usually it is used to build a fault-tolerant distributed state machine. 

In \paxos{} there are three roles: proposer, acceptor and learner. It is possible for nodes to fulfil only one or two of these roles. Usually, and for the rest of this explanation each node fulfills all three. To reach consensus on a new value we go through two phases: prepare and accept. Once the majority of the nodes has accepted a proposal the value included in that proposal has been chosen. Nodes keep track of the highest proposal number $n$ they have seen. 

Let us go through a \paxos{} iteration from the perspective of a node trying to share something, \textit{a value}. In the first phase a new \textit{value} is proposed by our node. It sends a \textit{prepare} request to a majority of acceptors. The request contains a proposal number $n$ higher than the highest number our node has seen up till now. The number is unique to our node\footnote{This can be done by having each node incrementing their number by the cluster size having initially assigned a number $0$ till \textit{cluster size} to each node.}. Each acceptor only responds if our number $n$ is the highest it has seen. If an acceptor had already accepted one or more requests it includes the accepted proposal with the highest $n$ in its response.

In phase two our node checks if it got a response from the majority. Our node is going to send an accept request back to those nodes that responded. The content of the accept request depends on what our node received in response to its prepare request:
%
\begin{enumerate}
	\item It received a response with number $n_p$. This means an acceptor has already accepted a value. If we continued with our own value the system would have two different accepted values. Therefor the content of our accept request will be the value from proposal $n_p$.
	\item It received only acknowledging replies and none contained a previously accepted value. The system has not yet decided on a value. The content of our accept request will be the value our node wants to propose but with our number $n$.
\end{enumerate}
%
Each acceptor accepts the request if it did not yet receive a prepare request numbered greater than $n$. On accepting a request an acceptor sends a message to all learners\footnote{Remember every node is a learner in this example.}. This way the learners learn a new value as soon as it's ready.

% Lets get a feeling for this by looking at what happens during network failure. Imagine the case where an accept with value $v_a$ is send to the majority $m$. The network fails and only $m-1$ nodes accept. Now 50\% of the nodes will reply $v_a$ as chosen value to learners. Any majority response to a propose request will include a node from $m-1$, thus with the accepted value. No accept request with another value then $v_a$ can therefore be send. Another value $v_b$ will thus never be accepted.

To get a feeling why this works we look at what happens during node failure. Imagine a case where a minimal majority $m$ accept value $v_a$. A single node in $m$ fails by pausing after the first learners learned of the now chosen value $v_a$. After freezing $m-1$ of the nodes will reply $v_a$ as value to learners. The learners will conclude no value has been chosen given $m-1$ is not a majority\footnote{This is not inconsistent, \paxos{} does not guarantee consistency over whether a value has been chosen.}. Acceptors change their value if they receive a higher numbered accept-request. If a single node changes its value to $v_b$ consensus will break since $v_a$ has already been seen as the chosen value by a learner. A new proposal that can result into higher numbered accept-requests needs a majority-response. A majority-response will include a node from $m-1$. That node will include $v_a$ as the accepted value. The value for the accept request then changes to $v_a$. No accept request with another value then $v_a$ can thus be issued. Another value $v_b$ will therefore never be accepted. The new accept request is issued to a majority adding at least one node to those having accepted $v_a$. Now at least $m+1$ nodes have $v_a$ as accepted value.

To build a distributed state machine you run multiple instances of \paxos{}. This is often referred to as \multipaxos{}. The value for each instance is a command to change the shared state. \multipaxos{} is not specified in literature and has never been verified.

\subsubsection*{Raft} \label{sec:raft}
The \paxos{} algorithm allows us to reach consensus on a single value. The \raft{} algorithm enables consent on a shared log. We can only append to and read from the log. The content of the log will always be the same on all nodes. As long as a majority of the nodes still function the log will be readable and appendable.

\raft{} maintains a single leader. Appending to the log is sequential because only the leader is allowed to append. The leader is decided on by a \textit{quorum}. There are two parts to \raft{}, \textit{electing leaders} and \textit{log replication}.

\subparagraph{Leader election} \label{sec:valid}
A \raft{}~\cite{raft} cluster starts without a leader and when it has a leader that leader can fail at any time. The cluster therefore must be able to reliable decide on a new leader at any time. Nodes in \raft{} start as followers, monitoring the leader by waiting for heartbeats. If a follower does not receive a heartbeat from a \emph{valid} leader on time it will try to become the leader, it becomes a candidate. In a fresh cluster without a leader one or more nodes become candidates.

\begin{figure}[htbp]
	\centering
	\includesvg{figs/papers/raft_states}
	\caption{A \raft{} node states. Most of the time all nodes except one are followers. One node is a leader. As failures are detected by time-outs the nodes change state. Adjusted from~\cite{raft}.}
	\label{fig:raft_states}
\end{figure}
%
A candidate tries to get itself elected. For that it needs the votes of a majority of the cluster. It asks all nodes for their vote. Note that servers vote only once and only if the candidate would become a \emph{valid} leader. If a majority of the cluster responds to a candidate with their vote that candidate becomes the leader. If it takes to long to receive a majority of the votes a candidate starts a fresh election. When there are multiple candidates requesting votes the vote might split\footnote{Election timeouts are randomized, therefore this does not repeat infinitely.}, no candidate then reaches a majority. A candidate immediately loses the election if it receives a heartbeat from a \emph{valid} leader. These state changes are illustrated in \cref{fig:raft_states}.

\begin{figure}[htbp]
	\centering
	\includesvg{figs/papers/raft_terms}
	\caption{An example of how time is divided in terms in a \raft{} cluster. Taken from~\cite{raft}.}
	\label{fig:raft_terms}
\end{figure}

In \raft{} time can be divided in terms. A term is a failed election where no node won or the period from the election of a leader to its failure, illustrated in \cref{fig:raft_terms}. Terms are used to determine the current leader, the leader with the highest terms. A heartbeat is \emph{valid} if, as far as the receiver knows, it originates from the current leader. A message can only be from the \textit{current} leader if the message \textit{term} is equal or higher than the receiving node's term. If a node receives a message with a higher term it updates its own to be that of the message.

When a node starts its \textit{term} is zero. If a node becomes a candidate it increments its \textit{term} by one. Now imagine a candidate with a \textit{term} equal or higher than that of the majority of the cluster. When receiving a vote request the majority will determine this candidate could become a \emph{valid} leader. This candidate will get the majority vote in the absence of another candidate and become \textit{the} leader.

\subparagraph{Log replication}
To append an entry to the log a leader sends an append-request to all nodes. Messages from \textit{invalid} leaders  are rejected. The leader knows an entry is committed after a majority of nodes acknowledged the append-request. For example entry 5 in \cref{fig:raft_entries} is committed. The leader includes the index up to which entries are committed in all its messages. This means entries will become committed on all followers at the latest with the next heartbeat. If the leader approaches the heartbeat timeout and no entry needs to be added it sends an empty append. There is no need for a special heartbeat message.

\begin{figure}[htbp]
	\centering
	\includesvg{figs/papers/raft_entries}
	\caption{Logs for multiple nodes. Each row is a different node. The log entries are commands to change shared variables $x$ and $y$ to different values. The shade boxes and the number at their top indicate the term. Taken from~\cite{raft}.}
	\label{fig:raft_entries}
\end{figure}

There are a few edge cases that require followers to be careful when appending. A follower may have an incomplete log if it did not receive a previous append (1), it may have messages the leader does not (2), and finally we must prevent a candidate missing committed entries from becoming the leader (3).
%
\begin{enumerate}
	\item To detect missing log entries, the entries are indexed incrementally. The leader includes the index of the previous entry and the term when it was appended in every append requests. If a followers last log entry does not match the included index and term the follower responds with an error. The leader will send its complete log for the follower to duplicate\footnote{This is rather inefficient, in the next paragraph we will come back to this.}.
	\item When a follower has entries the leader misses these will occupy indices the leader needs to use in the future. This happens when a previous leader crashed having pushed logs to some but not majority of followers. When the leader pushes a new entry with index $k$ such a follower will notice it already has an entry with index $k$. At that point it simply overwrites what it had at $k$.
	\item A new leader missing committed entries will push a wrong log to followers missing entries. For an entry to be committed it must be stored on the majority of the cluster. To win the election a node has to have the votes from the majority. Thus restricting followers to only vote for candidates that are as up-to-date as they are is enough. Followers therefore do not vote for a candidate with a lower log index then they themselves have.
\end{enumerate}

\subparagraph{Log compaction} \label{par:logcomp}
Keeping the entire log is rather inefficient. Especially as nodes are added and need to get send the entire log. Usually raft is used to build a state machine, in which case sending over the state is faster than the log. The state machine is a snapshot of the system, only valid for the moment in time it was taken. All nodes take snapshots independently of the leader. 

To take a snapshot a node writes the state machine to file together with the current \textit{term} and \textit{index}. It then discards all committed entries up to the snapshotted \textit{index} from its log. 

Followers that lag far behind are now send the snapshot and all logs that follow. The follower wipes its log before accepting the snapshot.

\subsubsection*{Consensus as a service}
So the problem of consensus has been solved, but the solutions are non-trivial to implement. We need to shape our application to fit the models the solutions use. If we are using \raft{} that means our systems must be built around a log. Then we need to build the application while being careful to implement the consensus algorithm correctly. A popular alternative is to use a coordination service instead. Here we look at \zookeeper{}~\cite{zookeeper} an example of a wait free coordination service. We first focus on the implementation, drawing parallels to \raft{} before we look at the \ac{api} \zookeeper{} exposes.

A \zookeeper{} cluster has a designated leader that replicates a database on all nodes. Only the leader can modify the database, therefore only the leader handles \textit{write} requests. The nodes handle \textit{read} requests themselves, \textit{write} requests are forwarded to the leader. To handle a \textit{write} requests \zookeeper{} relies on a consensus algorithm called \zab{}~\cite{zab}. It is an atomic broadcast capable of crash recovery. It uses a strong leader quite similar to \raft{} and guarantees that changes broadcast by the leader are delivered in the order they were sent and after changes from previous (crashed) leaders. \zab{} can deliver messages twice during recovery. To account for this \zookeeper{} turns change requests into \textit{idempotent} transactions. Theses can be applied multiple times with the same result.

\zookeeper{} exposes its strongly consistent database as a hierarchical name space (a tree) of \textsl{znodes}. Each \textsl{znode} contains a small amount of data and is identified by its \textsl{path}. Using the \ac{api} clients can operate on the znodes. They can: 
%
\begin{multicols}{2}
\begin{enumerate}
	\item Create new znodes
	\item Change the data in a znode
	\item Delete existing znodes
	\item Sync with the leader
	\item Query if a znode exists
	\item Read the data in a znode
	\item Get list of the children of the znode
\end{enumerate}
\end{multicols}
%
The last three operations support watching: the client getting a single notification when the result of the operation changed. This notification does not contain any information regarding the change. The value is no longer watched after the notification. Clients use watching to keep locally cached data is up-to-date. 

Clients communicating outside of \zookeeper{} might need special measures to ensure consistency. For example: client A updates a znode from value $v_1$ to value $v_2$ then communicates to client B, through another medium (lets say over \textsl{TCP/IP}). In this example client A and B are connected to different \zookeeper{} nodes. If the communication from A causes B to read the \textsl{znode} it will get the previous value $v_1$ from \zookeeper{} if the node it is connected to is lagging behind. Client B can avoid this by calling call \textit{sync}, this will make the zookeeper node processes all outstanding requests from the leader before returning.

\raft{} has the same race condition like issue. We might think we can just ensure a heartbeat has passed, by then all (functioning) node will be updated. This is not enough however, a faulty node could be suspended and not notice it is outdated. A solution is to include the last log index client A saw in its communication to client B. 

\paxos{} does not \textit{need} to suffer from this problem, but it can. In \paxos{} reading means asks a \textit{learner} for the value, the \textit{learner} can then ask the majority of the system if they have accepted a value and, if so, what it is. Usually \paxos{} is optimized by making acceptors inform learners of a change. In this case a leader that missed a message, that there is a value, from an acceptor will incorrectly return to client B there is no value.
